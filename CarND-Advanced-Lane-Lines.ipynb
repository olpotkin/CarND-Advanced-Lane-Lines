{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                 # NumPy\n",
    "import cv2                         # openCV\n",
    "import glob                        # Filename pattern matching\n",
    "import matplotlib.pyplot as plt    # 2D plotting\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Interactive plotting in separate window\n",
    "#%matplotlib qt\n",
    "\n",
    "# Visualizations will be shown in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute the camera calibration points using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_3d2d_points(do_plot=False, do_file=False):\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(8,5,0)\n",
    "    objp = np.zeros((6*9, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images\n",
    "    objpoints = []                     # 3D points in real world space\n",
    "    imgpoints = []                     # 2D points in image plain\n",
    "\n",
    "    # List of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "    print('Num of calibration images: {0}'.format(len(images)))\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for img_id, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        # http://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#findchessboardcorners\n",
    "        # cv2.findChessboardCorners(image, patternSize[, corners[, flags]]) â†’ retval, corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "        # If found - add object points, add image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9, 6), corners, ret)\n",
    "            # Draw the plot\n",
    "            if do_plot:\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "            # Save to the file\n",
    "            if do_file:\n",
    "                write_name = 'corners_' + str(img_id) + '.jpg'\n",
    "                cv2.imwrite(write_name, img)\n",
    "    return objpoints, imgpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def pickle_dump(mtx, dist):\n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump(dist_pickle, open('wide_dist_pickle.p', 'wb'))\n",
    "    \n",
    "def pickle_load():\n",
    "    # Getting back the camera calibration result:\n",
    "    with open('wide_dist_pickle.p', 'rb') as f:\n",
    "        dist_pickle = pickle.load(f)\n",
    "        return dist_pickle['mtx'], dist_pickle['dist']\n",
    "    \n",
    "def calibrate_camera(img):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    objpoints, imgpoints = get_3d2d_points(do_plot=False, do_file=False)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "    # Save the camera calibration result\n",
    "    pickle_dump(mtx, dist)\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Color/gradient threshold\n",
    "\n",
    "Combine color and gradient thresholds to generate a binary image where the lane lines are clearly visible.\n",
    "\n",
    "Output should be an array of the same size as the input image. The output array elements should be 1 where gradients were in the threshold range, and 0 everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For universal plotting of results\n",
    "def plot_row2(img1, img2, label_1, label_2, graysc=True):\n",
    "    # Plot the result (1 row with 2 images)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    f.tight_layout()\n",
    "    if graysc:\n",
    "        ax1.imshow(img1, cmap='gray')\n",
    "    else:\n",
    "        ax1.imshow(img1)\n",
    "    ax1.set_title(label_1, fontsize=16)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(label_2, fontsize=16)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply Sobel (Calculate directional gradient and Apply threshold)\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    #img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_gray = img_gray[:,:,2]\n",
    "    \n",
    "    # Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel) \n",
    "    # Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # Return mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Calculate gradient magnitude and Apply threshold\n",
    "# Return the magnitude of the gradient for a given sobel kernel \n",
    "# size and threshold values in both x and y\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    # img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_gray = img_gray[:,:,2]\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    # Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    # Return mask as binary_output image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Calculate gradient direction and Apply threshold\n",
    "# Compute the direction of the gradient and apply a threshold\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Convert to grayscale\n",
    "    #img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_gray = img_gray[:,:,2]\n",
    "    \n",
    "    # Take the gradient in x and y separately\n",
    "    sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the x and y gradients\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    # Use np.arctan2(abs_sobel_y, abs_sobel_x) to calculate the direction of the gradient\n",
    "    absgraddir = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "    # Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    # Return this mask as binary_output image\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_sobel_thresholds(img, do_plot=False):\n",
    "    # Sobel kernel size (choose a larger odd number to smooth gradient measurements)\n",
    "    ksize = 11\n",
    "    # Apply Sobel on x-axis\n",
    "    grad_x_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 120))\n",
    "    # Apply Sobel on y-axis\n",
    "    grad_y_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 120))\n",
    "    # Apply Sobel x and y, compute the magnitude of the gradient and apply a threshold\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 120))\n",
    "    # Apply Sobel x and y, computes the direction of the gradient and apply a threshold\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "    \n",
    "    # Combine the thresholds\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    #combined[((grad_x_binary == 1) & (grad_y_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined[((grad_x_binary == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_row2(image, grad_x_binary, 'Original Image', 'Sobel on x-axis')\n",
    "        plot_row2(image, grad_y_binary, 'Original Image', 'Sobel on y-axis')\n",
    "        plot_row2(image, mag_binary,    'Original Image', 'Thresholded Magnitude')\n",
    "        plot_row2(image, dir_binary,    'Original Image', 'Thresholded Gradient Direction')\n",
    "        plot_row2(image, combined,      'Original Image', 'Combined Thresholds')\n",
    "        \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def color_channel_threshold(img, thresh=(0, 255), do_plot=False):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extract S channel\n",
    "    s_channel = hls[:,:,2]\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "    \n",
    "    # Extract L channel\n",
    "    l_channel = hls[:,:,1]\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "    \n",
    "    # Combine S and L channels\n",
    "    combined = np.zeros_like(l_binary)\n",
    "    combined[((s_binary == 1) & (l_binary == 1))] = 1\n",
    "    \n",
    "    if do_plot:\n",
    "        plot_row2(image, s_binary, 'Original Image', 'S threshold')\n",
    "        plot_row2(image, l_binary, 'Original Image', 'L threshold')\n",
    "        plot_row2(image, combined, 'Original Image', 'S and L threshold')\n",
    "        \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Perspective transform\n",
    "\n",
    "Pick four points in a trapezoidal shape (similar to region masking) that would represent a rectangle when looking down on the road from above.\n",
    "\n",
    "The easiest way to do this is to investigate an image where the lane lines are straight, and find four points lying along the lines that, after perspective transform, make the lines look straight and vertical from a bird's eye view perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Applies an image mask.\n",
    "# Only keeps the region of the image defined by the polygon\n",
    "# formed from `vertices`. The rest of the image is set to black.\n",
    "def region_of_interest(img, vertices):\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    ignore_mask_color = 255\n",
    "    # Fill pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    # Return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def perspective_transform(img):\n",
    "    # Define 4 source points\n",
    "    src = np.float32([[200, img.shape[0]], \n",
    "                      [560, 470], \n",
    "                      [720, 470], \n",
    "                      [1115, img.shape[0]]])\n",
    "    # Define 4 destination points\n",
    "    dst = np.float32([[320, img.shape[0]], \n",
    "                      [320, 0], \n",
    "                      [960, 0], \n",
    "                      [960, img.shape[0]]])\n",
    "    # Use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Use cv2.warpPerspective() to warp image to a top-down view\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Detect lane lines\n",
    "\n",
    "Decide explicitly which pixels are part of the lines and which belong to the left line and which belong to the right line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Determine the lane curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# STEP 1: CAMERA CALIBRATION AND IMAGE UNDISTORTION\n",
    "######################################################\n",
    "# Test undistortion on the image\n",
    "img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "\n",
    "# Calibrate camera and save data to pickle\n",
    "mtx, dist = calibrate_camera(img)\n",
    "# Load calibration data from pickle\n",
    "#mtx, dist = pickle_load()\n",
    "\n",
    "# Undistort image\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# cv2.imwrite('test_undist.jpg', dst)\n",
    "\n",
    "# Visualize undistortion\n",
    "plot_row2(img, dst, 'Original Image', 'Undistorted Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# STEP 2: COLOR / GRADIENT THRESHOLD\n",
    "######################################################\n",
    "# Load original image from camera\n",
    "image = mpimg.imread('test_images/test2.jpg')\n",
    "#image = mpimg.imread('test_images/straight_lines2.jpg')\n",
    "# Undistort image\n",
    "undist_image = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "\n",
    "# Perform Sobel operations and combine thresholds\n",
    "combine_sobel = combine_sobel_thresholds(undist_image, do_plot=False)\n",
    "\n",
    "# Threshold color channel\n",
    "color_thresh = color_channel_threshold(undist_image, thresh=(110, 255), do_plot=False)\n",
    "\n",
    "# Combine color and gradient thresholds\n",
    "combined_binary = np.zeros_like(color_thresh)\n",
    "combined_binary[(combine_sobel == 1) | (color_thresh == 1)] = 1\n",
    "\n",
    "# Plot results\n",
    "#plot_row2(combine_sobel, color_thresh, 'Combined Sobel operations', 'S and L threshold', graysc=True)\n",
    "#plot_row2(undist_image, combined_binary, 'Original Image (Undistorted)', 'Final Thresholded Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# STEP 3: PERSPECTIVE TRANSFORM\n",
    "######################################################\n",
    "# Plot borders (for experiments)\n",
    "#plt.imshow(image)\n",
    "#plt.plot((200, 560), (image.shape[0], 470), 'k-', color='red', linewidth=1)\n",
    "#plt.plot((720, 1115), (470, image.shape[0]), 'k-', color='red', linewidth=1)\n",
    "warped_img = perspective_transform(combined_binary)\n",
    "#plot_row2(combined_binary, warped_img, 'Combined binary image', 'Warped image')\n",
    "\n",
    "# Define image mask (polygon of interest)\n",
    "imshape = warped_img.shape\n",
    "vertices = np.array([[(170, imshape[0]), \n",
    "                      (170, 0), \n",
    "                      (imshape[1] - 170, 0), \n",
    "                      (imshape[1]-170, imshape[0])]], dtype=np.int32)\n",
    "masked_img = region_of_interest(warped_img, vertices)\n",
    "\n",
    "plot_row2(warped_img, masked_img, 'Warped image', 'Warped image with mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# STEP 4: DETECT LANE LINES\n",
    "######################################################\n",
    "\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(masked_img[masked_img.shape[0]//2:,:], axis=0)\n",
    "#plt.plot(histogram)\n",
    "# Create an output image to draw on and  visualize the result\n",
    "out_img = np.dstack((masked_img, masked_img, masked_img))*255\n",
    "\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# The number of sliding windows\n",
    "nwindows = 9\n",
    "# Set height of windows\n",
    "window_height = np.int(masked_img.shape[0]/nwindows)\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = masked_img.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = masked_img.shape[0] - (window+1)*window_height\n",
    "    win_y_high = masked_img.shape[0] - window*window_height\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    \n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img, (win_xleft_low,win_y_low), (win_xleft_high,win_y_high), (0,255,0), 2) \n",
    "    cv2.rectangle(out_img, (win_xright_low,win_y_low), (win_xright_high,win_y_high), (0,255,0), 2)\n",
    "    \n",
    "     # Identify the nonzero pixels in x and y within the window\n",
    "    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                      (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                       (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    \n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(good_left_inds)\n",
    "    right_lane_inds.append(good_right_inds)\n",
    "    \n",
    "    # If founded > minpix pixels, recenter next window on their mean position\n",
    "    if len(good_left_inds) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "    if len(good_right_inds) > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "        \n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, masked_img.shape[0]-1, masked_img.shape[0])\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
